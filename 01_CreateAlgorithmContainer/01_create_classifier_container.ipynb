{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d39040f",
   "metadata": {},
   "source": [
    "# Building a docker container for training/deploying our classifier\n",
    "In this exercise we'll create a Docker image that will have the required code for training and deploying a ML model. In this particular example, we'll use scikit-learn (https://scikit-learn.org/) and the Random Forest Tree implementation of that library to train a flower classifier. The dataset used in this experiment is a toy dataset called Iris (http://archive.ics.uci.edu/ml/datasets/iris). The challenge itself is very basic, so you can focus on the mechanics and the features of this automated environment.\n",
    "\n",
    "A first pipeline will be executed at the end of this exercise, automatically. It will get the assets you'll push to a Git repo, build this image and push it to ECR, a docker image repository, used by SageMaker.\n",
    "\n",
    "Question: Why would I create a Scikit-learn container from scratch if SageMaker already offerst one (https://docs.aws.amazon.com/sagemaker/latest/dg/sklearn.html).\n",
    "Answer: This is an exercise and the idea here is also to show you how you can create your own container. In a real-life scenario, the best approach is to use the native container offered by SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ba9b44",
   "metadata": {},
   "source": [
    "## PART 1 - Creating the assets required to build/test a docker image\n",
    "### 1.1 Let's start by creating the training script!\n",
    "As you can see, this is a very basic example of Scikit-Learn. Nothing fancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb948473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def load_dataset(path):\n",
    "    # Take the set of files and read them all into a single pandas dataframe\n",
    "    files = [ os.path.join(path, file) for file in os.listdir(path) ]\n",
    "    \n",
    "    if len(files) == 0:\n",
    "        raise ValueError(\"Invalid # of files in dir: {}\".format(path))\n",
    "\n",
    "    raw_data = [ pd.read_csv(file, sep=\",\", header=None ) for file in files ]\n",
    "    data = pd.concat(raw_data)\n",
    "\n",
    "    # labels are in the first column\n",
    "    y = data.iloc[:,0]\n",
    "    X = data.iloc[:,1:]\n",
    "    return X,y\n",
    "    \n",
    "def start(args):\n",
    "    print(\"Training mode\")\n",
    "\n",
    "    try:\n",
    "        X_train, y_train = load_dataset(args.train)\n",
    "        X_test, y_test = load_dataset(args.validation)\n",
    "        \n",
    "        hyperparameters = {\n",
    "            \"max_depth\": args.max_depth,\n",
    "            \"verbose\": 1, # show all logs\n",
    "            \"n_jobs\": args.n_jobs,\n",
    "            \"n_estimators\": args.n_estimators\n",
    "        }\n",
    "        print(\"Training the classifier\")\n",
    "        model = RandomForestClassifier()\n",
    "        model.set_params(**hyperparameters)\n",
    "        model.fit(X_train, y_train)\n",
    "        print(\"Score: {}\".format( model.score(X_test, y_test)) )\n",
    "        joblib.dump(model, open(os.path.join(args.model_dir, \"iris_model.pkl\"), \"wb\"))\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failureReason in the\n",
    "        # DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(args.output_dir, \"failure\"), \"w\") as s:\n",
    "            s.write(\"Exception during training: \" + str(e) + \"\\\\n\" + trc)\n",
    "            \n",
    "        # Printing this causes the exception to be in the training job logs, as well.\n",
    "        print(\"Exception during training: \" + str(e) + \"\\\\n\" + trc, file=sys.stderr)\n",
    "        \n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb2f753",
   "metadata": {},
   "source": [
    "### 1.2 Ok. Lets then create the handler. The Inference Handler is how we use the SageMaker Inference Toolkit to encapsulate our code and expose it as a SageMaker container.\n",
    "SageMaker Inference Toolkit: https://github.com/aws/sagemaker-inference-toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab67e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile handler.py\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from sagemaker_inference.default_inference_handler import DefaultInferenceHandler\n",
    "from sagemaker_inference.default_handler_service import DefaultHandlerService\n",
    "from sagemaker_inference import content_types, errors, transformer, encoder, decoder\n",
    "\n",
    "class HandlerService(DefaultHandlerService, DefaultInferenceHandler):\n",
    "    def __init__(self):\n",
    "        op = transformer.Transformer(default_inference_handler=self)\n",
    "        super(HandlerService, self).__init__(transformer=op)\n",
    "    \n",
    "    ## Loads the model from the disk\n",
    "    def default_model_fn(self, model_dir):\n",
    "        model_filename = os.path.join(model_dir, \"iris_model.pkl\")\n",
    "        return joblib.load(open(model_filename, \"rb\"))\n",
    "    \n",
    "    ## Parse and check the format of the input data\n",
    "    def default_input_fn(self, input_data, content_type):\n",
    "        if content_type != \"text/csv\":\n",
    "            raise Exception(\"Invalid content-type: %s\" % content_type)\n",
    "        return decoder.decode(input_data, content_type).reshape(1,-1)\n",
    "    \n",
    "    ## Run our model and do the prediction\n",
    "    def default_predict_fn(self, payload, model):\n",
    "        return model.predict( payload ).tolist()\n",
    "    \n",
    "    ## Gets the prediction output and format it to be returned to the user\n",
    "    def default_output_fn(self, prediction, accept):\n",
    "        if accept != \"text/csv\":\n",
    "            raise Exception(\"Invalid accept: %s\" % accept)\n",
    "        return encoder.encode(prediction, accept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d523c1",
   "metadata": {},
   "source": [
    "### 1.3 Now we need to create the entrypoint of our container. The main function\n",
    "We'll use SageMaker Training Toolkit (https://github.com/aws/sagemaker-training-toolkit) to work with the arguments and environment variables defined by SageMaker. This library will make our code simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4b9c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import train\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import traceback\n",
    "from sagemaker_inference import model_server\n",
    "from sagemaker_training import environment\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2 or ( not sys.argv[1] in [ \"serve\", \"train\" ] ):\n",
    "        raise Exception(\"Invalid argument: you must inform 'train' for training mode or 'serve' predicting mode\") \n",
    "        \n",
    "    if sys.argv[1] == \"train\":\n",
    "        \n",
    "        env = environment.Environment()\n",
    "        \n",
    "        parser = argparse.ArgumentParser()\n",
    "        # https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md\n",
    "        parser.add_argument(\"--max-depth\", type=int, default=10)\n",
    "        parser.add_argument(\"--n-jobs\", type=int, default=env.num_cpus)\n",
    "        parser.add_argument(\"--n-estimators\", type=int, default=120)\n",
    "        \n",
    "        # reads input channels training and testing from the environment variables\n",
    "        parser.add_argument(\"--train\", type=str, default=env.channel_input_dirs[\"train\"])\n",
    "        parser.add_argument(\"--validation\", type=str, default=env.channel_input_dirs[\"validation\"])\n",
    "\n",
    "        parser.add_argument(\"--model-dir\", type=str, default=env.model_dir)\n",
    "        parser.add_argument(\"--output-dir\", type=str, default=env.output_dir)\n",
    "        \n",
    "        args,unknown = parser.parse_known_args()\n",
    "        train.start(args)\n",
    "    else:\n",
    "        model_server.start_model_server(handler_service=\"serving.handler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb5583",
   "metadata": {},
   "source": [
    "### 1.4 Then, we can create the Dockerfile\n",
    "Just pay attention to the packages we'll install in our container. Here, we'll use SageMaker Inference Toolkit (https://github.com/aws/sagemaker-inference-toolkit) and SageMaker Training Toolkit (https://github.com/aws/sagemaker-training-toolkit) to prepare the container for training/serving our model. By serving you can understand: exposing our model as a webservice that can be called through an api call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165744ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM python:3.7-buster\n",
    "\n",
    "# Set a docker label to advertise multi-model support on the container\n",
    "LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
    "# Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
    "RUN rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
    "RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
    "\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
    "\n",
    "COPY main.py /opt/ml/code/main.py\n",
    "COPY train.py /opt/ml/code/train.py\n",
    "COPY handler.py /opt/ml/code/serving/handler.py\n",
    "\n",
    "ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a890447",
   "metadata": {},
   "source": [
    "### 1.5 Finally, let's create the buildspec\n",
    "This file will be used by CodeBuild for creating our Container image.\n",
    "With this file, CodeBuild will run the \"docker build\" command, using the assets we created above, and deploy the image to the Registry.\n",
    "As you can see, each command is a bash command that will be executed from inside a Linux Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea689b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting buildspec.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile buildspec.yml\n",
    "version: 0.2\n",
    "\n",
    "phases:\n",
    "  install:\n",
    "    runtime-versions:\n",
    "      docker: 18\n",
    "\n",
    "  pre_build:\n",
    "    commands:\n",
    "      - echo Logging in to Amazon ECR...\n",
    "      - $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
    "  build:\n",
    "    commands:\n",
    "      - echo Build started on `date`\n",
    "      - echo Building the Docker image...\n",
    "      - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG .\n",
    "      - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "\n",
    "  post_build:\n",
    "    commands:\n",
    "      - echo Build completed on `date`\n",
    "      - echo Pushing the Docker image...\n",
    "      - echo docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
    "      - echo $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG > image.url\n",
    "      - echo Done\n",
    "artifacts:\n",
    "  files:\n",
    "    - image.url\n",
    "  name: image_url\n",
    "  discard-paths: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c98fa",
   "metadata": {},
   "source": [
    "## PART 2 - Local Test: Let's build the image locally and do some tests\n",
    "### 2.1 Building the image locally, first\n",
    "Each SageMaker Jupyter Notebook already has a docker envorinment pre-installed. So we can play with Docker containers just using the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42abe93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon    233kB\n",
      "Step 1/14 : FROM python:3.7-buster\n",
      " ---> de1fe4b12444\n",
      "Step 2/14 : LABEL com.amazonaws.sagemaker.capabilities.multi-models=false\n",
      " ---> Using cache\n",
      " ---> 7f7394407f70\n",
      "Step 3/14 : LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
      " ---> Running in db7d90104242\n",
      "Removing intermediate container db7d90104242\n",
      " ---> b6962f4b2fb1\n",
      "Step 4/14 : RUN apt-get update -y && apt-get -y install --no-install-recommends default-jdk\n",
      " ---> Running in 07407b4da94d\n",
      "Get:1 http://deb.debian.org/debian buster InRelease [122 kB]\n",
      "Get:2 http://deb.debian.org/debian-security buster/updates InRelease [34.8 kB]\n",
      "Get:3 http://deb.debian.org/debian buster-updates InRelease [56.6 kB]\n",
      "Get:4 http://deb.debian.org/debian buster/main amd64 Packages [7911 kB]\n",
      "Get:5 http://deb.debian.org/debian-security buster/updates/main amd64 Packages [347 kB]\n",
      "Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages [8788 B]\n",
      "Fetched 8479 kB in 2s (5022 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  ca-certificates-java default-jdk-headless default-jre default-jre-headless\n",
      "  java-common libasound2 libasound2-data libavahi-client3 libavahi-common-data\n",
      "  libavahi-common3 libcups2 libdbus-1-3 libdrm-amdgpu1 libdrm-common\n",
      "  libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libgif7 libgl1\n",
      "  libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libllvm7\n",
      "  libnspr4 libnss3 libpciaccess0 libpcsclite1 libsensors-config libsensors5\n",
      "  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n",
      "  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxtst6\n",
      "  libxxf86vm1 openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
      "  openjdk-11-jre-headless\n",
      "Suggested packages:\n",
      "  libasound2-plugins alsa-utils cups-common pciutils pcscd lm-sensors\n",
      "  openjdk-11-demo openjdk-11-source visualvm libnss-mdns fonts-dejavu-extra\n",
      "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
      "  | fonts-wqy-zenhei fonts-indic\n",
      "Recommended packages:\n",
      "  dbus libatk-wrapper-java-jni fonts-dejavu-extra\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates-java default-jdk default-jdk-headless default-jre\n",
      "  default-jre-headless java-common libasound2 libasound2-data libavahi-client3\n",
      "  libavahi-common-data libavahi-common3 libcups2 libdbus-1-3 libdrm-amdgpu1\n",
      "  libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2 libgif7\n",
      "  libgl1 libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0 libllvm7\n",
      "  libnspr4 libnss3 libpciaccess0 libpcsclite1 libsensors-config libsensors5\n",
      "  libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0\n",
      "  libxcb-sync1 libxdamage1 libxfixes3 libxi6 libxshmfence1 libxtst6\n",
      "  libxxf86vm1 openjdk-11-jdk openjdk-11-jdk-headless openjdk-11-jre\n",
      "  openjdk-11-jre-headless\n",
      "0 upgraded, 49 newly installed, 0 to remove and 4 not upgraded.\n",
      "Need to get 289 MB of archives.\n",
      "After this operation, 633 MB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 java-common all 0.71 [14.4 kB]\n",
      "Get:2 http://deb.debian.org/debian buster/main amd64 libavahi-common-data amd64 0.7-4+deb10u1 [122 kB]\n",
      "Get:3 http://deb.debian.org/debian buster/main amd64 libavahi-common3 amd64 0.7-4+deb10u1 [54.4 kB]\n",
      "Get:4 http://deb.debian.org/debian buster/main amd64 libdbus-1-3 amd64 1.12.20-0+deb10u1 [215 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 libavahi-client3 amd64 0.7-4+deb10u1 [58.2 kB]\n",
      "Get:6 http://deb.debian.org/debian-security buster/updates/main amd64 libcups2 amd64 2.2.10-6+deb10u6 [325 kB]\n",
      "Get:7 http://deb.debian.org/debian buster/main amd64 libnspr4 amd64 2:4.20-1 [112 kB]\n",
      "Get:8 http://deb.debian.org/debian buster/main amd64 libnss3 amd64 2:3.42.1-1+deb10u5 [1160 kB]\n",
      "Get:9 http://deb.debian.org/debian buster/main amd64 libasound2-data all 1.1.8-1 [59.6 kB]\n",
      "Get:10 http://deb.debian.org/debian buster/main amd64 libasound2 amd64 1.1.8-1 [361 kB]\n",
      "Get:11 http://deb.debian.org/debian buster/main amd64 libpcsclite1 amd64 1.8.24-1 [58.5 kB]\n",
      "Get:12 http://deb.debian.org/debian-security buster/updates/main amd64 openjdk-11-jre-headless amd64 11.0.16+8-1~deb10u1 [37.3 MB]\n",
      "Get:13 http://deb.debian.org/debian buster/main amd64 default-jre-headless amd64 2:1.11-71 [10.9 kB]\n",
      "Get:14 http://deb.debian.org/debian buster/main amd64 ca-certificates-java all 20190405 [15.7 kB]\n",
      "Get:15 http://deb.debian.org/debian buster/main amd64 libglvnd0 amd64 1.1.0-1 [48.6 kB]\n",
      "Get:16 http://deb.debian.org/debian buster/main amd64 libdrm-common all 2.4.97-1 [13.8 kB]\n",
      "Get:17 http://deb.debian.org/debian buster/main amd64 libdrm2 amd64 2.4.97-1 [39.7 kB]\n",
      "Get:18 http://deb.debian.org/debian buster/main amd64 libglapi-mesa amd64 18.3.6-2+deb10u1 [66.3 kB]\n",
      "Get:19 http://deb.debian.org/debian buster/main amd64 libx11-xcb1 amd64 2:1.6.7-1+deb10u2 [191 kB]\n",
      "Get:20 http://deb.debian.org/debian buster/main amd64 libxcb-dri2-0 amd64 1.13.1-2 [101 kB]\n",
      "Get:21 http://deb.debian.org/debian buster/main amd64 libxcb-dri3-0 amd64 1.13.1-2 [100 kB]\n",
      "Get:22 http://deb.debian.org/debian buster/main amd64 libxcb-glx0 amd64 1.13.1-2 [116 kB]\n",
      "Get:23 http://deb.debian.org/debian buster/main amd64 libxcb-present0 amd64 1.13.1-2 [99.1 kB]\n",
      "Get:24 http://deb.debian.org/debian buster/main amd64 libxcb-sync1 amd64 1.13.1-2 [103 kB]\n",
      "Get:25 http://deb.debian.org/debian buster/main amd64 libxfixes3 amd64 1:5.0.3-1 [21.9 kB]\n",
      "Get:26 http://deb.debian.org/debian buster/main amd64 libxdamage1 amd64 1:1.1.4-3+b3 [14.9 kB]\n",
      "Get:27 http://deb.debian.org/debian buster/main amd64 libxshmfence1 amd64 1.3-1 [8820 B]\n",
      "Get:28 http://deb.debian.org/debian buster/main amd64 libxxf86vm1 amd64 1:1.1.4-1+b2 [20.8 kB]\n",
      "Get:29 http://deb.debian.org/debian buster/main amd64 libdrm-amdgpu1 amd64 2.4.97-1 [27.3 kB]\n",
      "Get:30 http://deb.debian.org/debian buster/main amd64 libpciaccess0 amd64 0.14-1 [53.5 kB]\n",
      "Get:31 http://deb.debian.org/debian buster/main amd64 libdrm-intel1 amd64 2.4.97-1 [69.8 kB]\n",
      "Get:32 http://deb.debian.org/debian buster/main amd64 libdrm-nouveau2 amd64 2.4.97-1 [26.3 kB]\n",
      "Get:33 http://deb.debian.org/debian buster/main amd64 libdrm-radeon1 amd64 2.4.97-1 [31.1 kB]\n",
      "Get:34 http://deb.debian.org/debian buster/main amd64 libllvm7 amd64 1:7.0.1-8+deb10u2 [13.1 MB]\n",
      "Get:35 http://deb.debian.org/debian buster/main amd64 libsensors-config all 1:3.5.0-3 [31.6 kB]\n",
      "Get:36 http://deb.debian.org/debian buster/main amd64 libsensors5 amd64 1:3.5.0-3 [52.6 kB]\n",
      "Get:37 http://deb.debian.org/debian buster/main amd64 libgl1-mesa-dri amd64 18.3.6-2+deb10u1 [6685 kB]\n",
      "Get:38 http://deb.debian.org/debian buster/main amd64 libglx-mesa0 amd64 18.3.6-2+deb10u1 [180 kB]\n",
      "Get:39 http://deb.debian.org/debian buster/main amd64 libglx0 amd64 1.1.0-1 [30.0 kB]\n",
      "Get:40 http://deb.debian.org/debian buster/main amd64 libgl1 amd64 1.1.0-1 [91.1 kB]\n",
      "Get:41 http://deb.debian.org/debian buster/main amd64 libgif7 amd64 5.1.4-3 [43.3 kB]\n",
      "Get:42 http://deb.debian.org/debian buster/main amd64 libxi6 amd64 2:1.7.9-1 [82.6 kB]\n",
      "Get:43 http://deb.debian.org/debian buster/main amd64 libxtst6 amd64 2:1.2.3-1 [27.8 kB]\n",
      "Get:44 http://deb.debian.org/debian-security buster/updates/main amd64 openjdk-11-jre amd64 11.0.16+8-1~deb10u1 [174 kB]\n",
      "Get:45 http://deb.debian.org/debian buster/main amd64 default-jre amd64 2:1.11-71 [1044 B]\n",
      "Get:46 http://deb.debian.org/debian-security buster/updates/main amd64 openjdk-11-jdk-headless amd64 11.0.16+8-1~deb10u1 [221 MB]\n",
      "Get:47 http://deb.debian.org/debian buster/main amd64 default-jdk-headless amd64 2:1.11-71 [1104 B]\n",
      "Get:48 http://deb.debian.org/debian-security buster/updates/main amd64 openjdk-11-jdk amd64 11.0.16+8-1~deb10u1 [7073 kB]\n",
      "Get:49 http://deb.debian.org/debian buster/main amd64 default-jdk amd64 2:1.11-71 [1056 B]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 289 MB in 4s (72.2 MB/s)\n",
      "Selecting previously unselected package java-common.\n",
      "(Reading database ... 24614 files and directories currently installed.)\n",
      "Preparing to unpack .../00-java-common_0.71_all.deb ...\n",
      "Unpacking java-common (0.71) ...\n",
      "Selecting previously unselected package libavahi-common-data:amd64.\n",
      "Preparing to unpack .../01-libavahi-common-data_0.7-4+deb10u1_amd64.deb ...\n",
      "Unpacking libavahi-common-data:amd64 (0.7-4+deb10u1) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libavahi-common3:amd64.\n",
      "Preparing to unpack .../02-libavahi-common3_0.7-4+deb10u1_amd64.deb ...\n",
      "Unpacking libavahi-common3:amd64 (0.7-4+deb10u1) ...\n",
      "Selecting previously unselected package libdbus-1-3:amd64.\n",
      "Preparing to unpack .../03-libdbus-1-3_1.12.20-0+deb10u1_amd64.deb ...\n",
      "Unpacking libdbus-1-3:amd64 (1.12.20-0+deb10u1) ...\n",
      "Selecting previously unselected package libavahi-client3:amd64.\n",
      "Preparing to unpack .../04-libavahi-client3_0.7-4+deb10u1_amd64.deb ...\n",
      "Unpacking libavahi-client3:amd64 (0.7-4+deb10u1) ...\n",
      "Selecting previously unselected package libcups2:amd64.\n",
      "Preparing to unpack .../05-libcups2_2.2.10-6+deb10u6_amd64.deb ...\n",
      "Unpacking libcups2:amd64 (2.2.10-6+deb10u6) ...\n",
      "Selecting previously unselected package libnspr4:amd64.\n",
      "Preparing to unpack .../06-libnspr4_2%3a4.20-1_amd64.deb ...\n",
      "Unpacking libnspr4:amd64 (2:4.20-1) ...\n",
      "Selecting previously unselected package libnss3:amd64.\n",
      "Preparing to unpack .../07-libnss3_2%3a3.42.1-1+deb10u5_amd64.deb ...\n",
      "Unpacking libnss3:amd64 (2:3.42.1-1+deb10u5) ...\n",
      "Selecting previously unselected package libasound2-data.\n",
      "Preparing to unpack .../08-libasound2-data_1.1.8-1_all.deb ...\n",
      "Unpacking libasound2-data (1.1.8-1) ...\n",
      "Selecting previously unselected package libasound2:amd64.\n",
      "Preparing to unpack .../09-libasound2_1.1.8-1_amd64.deb ...\n",
      "Unpacking libasound2:amd64 (1.1.8-1) ...\n",
      "Selecting previously unselected package libpcsclite1:amd64.\n",
      "Preparing to unpack .../10-libpcsclite1_1.8.24-1_amd64.deb ...\n",
      "Unpacking libpcsclite1:amd64 (1.8.24-1) ...\n",
      "Selecting previously unselected package openjdk-11-jre-headless:amd64.\n",
      "Preparing to unpack .../11-openjdk-11-jre-headless_11.0.16+8-1~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jre-headless:amd64 (11.0.16+8-1~deb10u1) ...\n",
      "Selecting previously unselected package default-jre-headless.\n",
      "Preparing to unpack .../12-default-jre-headless_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jre-headless (2:1.11-71) ...\n",
      "Selecting previously unselected package ca-certificates-java.\n",
      "Preparing to unpack .../13-ca-certificates-java_20190405_all.deb ...\n",
      "Unpacking ca-certificates-java (20190405) ...\n",
      "Selecting previously unselected package libglvnd0:amd64.\n",
      "Preparing to unpack .../14-libglvnd0_1.1.0-1_amd64.deb ...\n",
      "Unpacking libglvnd0:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libdrm-common.\n",
      "Preparing to unpack .../15-libdrm-common_2.4.97-1_all.deb ...\n",
      "Unpacking libdrm-common (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "Preparing to unpack .../16-libdrm2_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../17-libglapi-mesa_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (18.3.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../18-libx11-xcb1_2%3a1.6.7-1+deb10u2_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.6.7-1+deb10u2) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../19-libxcb-dri2-0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../20-libxcb-dri3-0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../21-libxcb-glx0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../22-libxcb-present0_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../23-libxcb-sync1_1.13.1-2_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.13.1-2) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../24-libxfixes3_1%3a5.0.3-1_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:5.0.3-1) ...\n",
      "Selecting previously unselected package libxdamage1:amd64.\n",
      "Preparing to unpack .../25-libxdamage1_1%3a1.1.4-3+b3_amd64.deb ...\n",
      "Unpacking libxdamage1:amd64 (1:1.1.4-3+b3) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../26-libxshmfence1_1.3-1_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.3-1) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../27-libxxf86vm1_1%3a1.1.4-1+b2_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.4-1+b2) ...\n",
      "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
      "Preparing to unpack .../28-libdrm-amdgpu1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-amdgpu1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libpciaccess0:amd64.\n",
      "Preparing to unpack .../29-libpciaccess0_0.14-1_amd64.deb ...\n",
      "Unpacking libpciaccess0:amd64 (0.14-1) ...\n",
      "Selecting previously unselected package libdrm-intel1:amd64.\n",
      "Preparing to unpack .../30-libdrm-intel1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-intel1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
      "Preparing to unpack .../31-libdrm-nouveau2_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-nouveau2:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libdrm-radeon1:amd64.\n",
      "Preparing to unpack .../32-libdrm-radeon1_2.4.97-1_amd64.deb ...\n",
      "Unpacking libdrm-radeon1:amd64 (2.4.97-1) ...\n",
      "Selecting previously unselected package libllvm7:amd64.\n",
      "Preparing to unpack .../33-libllvm7_1%3a7.0.1-8+deb10u2_amd64.deb ...\n",
      "Unpacking libllvm7:amd64 (1:7.0.1-8+deb10u2) ...\n",
      "Selecting previously unselected package libsensors-config.\n",
      "Preparing to unpack .../34-libsensors-config_1%3a3.5.0-3_all.deb ...\n",
      "Unpacking libsensors-config (1:3.5.0-3) ...\n",
      "Selecting previously unselected package libsensors5:amd64.\n",
      "Preparing to unpack .../35-libsensors5_1%3a3.5.0-3_amd64.deb ...\n",
      "Unpacking libsensors5:amd64 (1:3.5.0-3) ...\n",
      "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
      "Preparing to unpack .../36-libgl1-mesa-dri_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dri:amd64 (18.3.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libglx-mesa0:amd64.\n",
      "Preparing to unpack .../37-libglx-mesa0_18.3.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libglx-mesa0:amd64 (18.3.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libglx0:amd64.\n",
      "Preparing to unpack .../38-libglx0_1.1.0-1_amd64.deb ...\n",
      "Unpacking libglx0:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libgl1:amd64.\n",
      "Preparing to unpack .../39-libgl1_1.1.0-1_amd64.deb ...\n",
      "Unpacking libgl1:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package libgif7:amd64.\n",
      "Preparing to unpack .../40-libgif7_5.1.4-3_amd64.deb ...\n",
      "Unpacking libgif7:amd64 (5.1.4-3) ...\n",
      "Selecting previously unselected package libxi6:amd64.\n",
      "Preparing to unpack .../41-libxi6_2%3a1.7.9-1_amd64.deb ...\n",
      "Unpacking libxi6:amd64 (2:1.7.9-1) ...\n",
      "Selecting previously unselected package libxtst6:amd64.\n",
      "Preparing to unpack .../42-libxtst6_2%3a1.2.3-1_amd64.deb ...\n",
      "Unpacking libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Selecting previously unselected package openjdk-11-jre:amd64.\n",
      "Preparing to unpack .../43-openjdk-11-jre_11.0.16+8-1~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jre:amd64 (11.0.16+8-1~deb10u1) ...\n",
      "Selecting previously unselected package default-jre.\n",
      "Preparing to unpack .../44-default-jre_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jre (2:1.11-71) ...\n",
      "Selecting previously unselected package openjdk-11-jdk-headless:amd64.\n",
      "Preparing to unpack .../45-openjdk-11-jdk-headless_11.0.16+8-1~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jdk-headless:amd64 (11.0.16+8-1~deb10u1) ...\n",
      "Selecting previously unselected package default-jdk-headless.\n",
      "Preparing to unpack .../46-default-jdk-headless_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jdk-headless (2:1.11-71) ...\n",
      "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
      "Preparing to unpack .../47-openjdk-11-jdk_11.0.16+8-1~deb10u1_amd64.deb ...\n",
      "Unpacking openjdk-11-jdk:amd64 (11.0.16+8-1~deb10u1) ...\n",
      "Selecting previously unselected package default-jdk.\n",
      "Preparing to unpack .../48-default-jdk_2%3a1.11-71_amd64.deb ...\n",
      "Unpacking default-jdk (2:1.11-71) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.13.1-2) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.6.7-1+deb10u2) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up libpciaccess0:amd64 (0.14-1) ...\n",
      "Setting up libxi6:amd64 (2:1.7.9-1) ...\n",
      "Setting up java-common (0.71) ...\n",
      "Setting up libglvnd0:amd64 (1.1.0-1) ...\n",
      "Setting up libxtst6:amd64 (2:1.2.3-1) ...\n",
      "Setting up libxcb-glx0:amd64 (1.13.1-2) ...\n",
      "Setting up libsensors-config (1:3.5.0-3) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.4-1+b2) ...\n",
      "Setting up libxcb-present0:amd64 (1.13.1-2) ...\n",
      "Setting up libasound2-data (1.1.8-1) ...\n",
      "Setting up libnspr4:amd64 (2:4.20-1) ...\n",
      "Setting up libxfixes3:amd64 (1:5.0.3-1) ...\n",
      "Setting up libxcb-sync1:amd64 (1.13.1-2) ...\n",
      "Setting up libavahi-common-data:amd64 (0.7-4+deb10u1) ...\n",
      "Setting up libdbus-1-3:amd64 (1.12.20-0+deb10u1) ...\n",
      "Setting up libpcsclite1:amd64 (1.8.24-1) ...\n",
      "Setting up libsensors5:amd64 (1:3.5.0-3) ...\n",
      "Setting up libglapi-mesa:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.13.1-2) ...\n",
      "Setting up libgif7:amd64 (5.1.4-3) ...\n",
      "Setting up libxshmfence1:amd64 (1.3-1) ...\n",
      "Setting up libasound2:amd64 (1.1.8-1) ...\n",
      "Setting up libllvm7:amd64 (1:7.0.1-8+deb10u2) ...\n",
      "Setting up libdrm-common (2.4.97-1) ...\n",
      "Setting up libxdamage1:amd64 (1:1.1.4-3+b3) ...\n",
      "Setting up libavahi-common3:amd64 (0.7-4+deb10u1) ...\n",
      "Setting up libnss3:amd64 (2:3.42.1-1+deb10u5) ...\n",
      "Setting up libdrm2:amd64 (2.4.97-1) ...\n",
      "Setting up libavahi-client3:amd64 (0.7-4+deb10u1) ...\n",
      "Setting up libdrm-amdgpu1:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-nouveau2:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-radeon1:amd64 (2.4.97-1) ...\n",
      "Setting up libdrm-intel1:amd64 (2.4.97-1) ...\n",
      "Setting up libgl1-mesa-dri:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libcups2:amd64 (2.2.10-6+deb10u6) ...\n",
      "Setting up libglx-mesa0:amd64 (18.3.6-2+deb10u1) ...\n",
      "Setting up libglx0:amd64 (1.1.0-1) ...\n",
      "Setting up libgl1:amd64 (1.1.0-1) ...\n",
      "Setting up ca-certificates-java (20190405) ...\n",
      "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
      "Adding debian:ACCVRAIZ1.pem\n",
      "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
      "Adding debian:Actalis_Authentication_Root_CA.pem\n",
      "Adding debian:AffirmTrust_Commercial.pem\n",
      "Adding debian:AffirmTrust_Networking.pem\n",
      "Adding debian:AffirmTrust_Premium.pem\n",
      "Adding debian:AffirmTrust_Premium_ECC.pem\n",
      "Adding debian:Amazon_Root_CA_1.pem\n",
      "Adding debian:Amazon_Root_CA_2.pem\n",
      "Adding debian:Amazon_Root_CA_3.pem\n",
      "Adding debian:Amazon_Root_CA_4.pem\n",
      "Adding debian:Atos_TrustedRoot_2011.pem\n",
      "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
      "Adding debian:Baltimore_CyberTrust_Root.pem\n",
      "Adding debian:Buypass_Class_2_Root_CA.pem\n",
      "Adding debian:Buypass_Class_3_Root_CA.pem\n",
      "Adding debian:CA_Disig_Root_R2.pem\n",
      "Adding debian:CFCA_EV_ROOT.pem\n",
      "Adding debian:COMODO_Certification_Authority.pem\n",
      "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
      "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
      "Adding debian:Certigna.pem\n",
      "Adding debian:Certigna_Root_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA.pem\n",
      "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
      "Adding debian:Chambers_of_Commerce_Root_-_2008.pem\n",
      "Adding debian:Comodo_AAA_Services_root.pem\n",
      "Adding debian:Cybertrust_Global_Root.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
      "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
      "Adding debian:DST_Root_CA_X3.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
      "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
      "Adding debian:DigiCert_Global_Root_CA.pem\n",
      "Adding debian:DigiCert_Global_Root_G2.pem\n",
      "Adding debian:DigiCert_Global_Root_G3.pem\n",
      "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
      "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
      "Adding debian:E-Tugra_Certification_Authority.pem\n",
      "Adding debian:EC-ACC.pem\n",
      "Adding debian:EE_Certification_Centre_Root_CA.pem\n",
      "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority.pem\n",
      "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
      "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
      "Adding debian:GTS_Root_R1.pem\n",
      "Adding debian:GTS_Root_R2.pem\n",
      "Adding debian:GTS_Root_R3.pem\n",
      "Adding debian:GTS_Root_R4.pem\n",
      "Adding debian:GeoTrust_Global_CA.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority_-_G2.pem\n",
      "Adding debian:GeoTrust_Primary_Certification_Authority_-_G3.pem\n",
      "Adding debian:GeoTrust_Universal_CA.pem\n",
      "Adding debian:GeoTrust_Universal_CA_2.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
      "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
      "Adding debian:GlobalSign_Root_CA.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R2.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
      "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
      "Adding debian:Global_Chambersign_Root_-_2008.pem\n",
      "Adding debian:Go_Daddy_Class_2_CA.pem\n",
      "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2011.pem\n",
      "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_1.pem\n",
      "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
      "Adding debian:ISRG_Root_X1.pem\n",
      "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
      "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
      "Adding debian:Izenpe.com.pem\n",
      "Adding debian:LuxTrust_Global_Root_2.pem\n",
      "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
      "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
      "Adding debian:Network_Solutions_Certificate_Authority.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GA_CA.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
      "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA.pem\n",
      "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
      "Adding debian:QuoVadis_Root_CA_2.pem\n",
      "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
      "Adding debian:QuoVadis_Root_CA_3.pem\n",
      "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
      "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
      "Adding debian:SZAFIR_ROOT_CA2.pem\n",
      "Adding debian:SecureSign_RootCA11.pem\n",
      "Adding debian:SecureTrust_CA.pem\n",
      "Adding debian:Secure_Global_CA.pem\n",
      "Adding debian:Security_Communication_RootCA2.pem\n",
      "Adding debian:Security_Communication_Root_CA.pem\n",
      "Adding debian:Sonera_Class_2_Root_CA.pem\n",
      "Adding debian:Staat_der_Nederlanden_EV_Root_CA.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G2.pem\n",
      "Adding debian:Staat_der_Nederlanden_Root_CA_-_G3.pem\n",
      "Adding debian:Starfield_Class_2_CA.pem\n",
      "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
      "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
      "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
      "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
      "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
      "Adding debian:TWCA_Global_Root_CA.pem\n",
      "Adding debian:TWCA_Root_Certification_Authority.pem\n",
      "Adding debian:Taiwan_GRCA.pem\n",
      "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
      "Adding debian:TrustCor_ECA-1.pem\n",
      "Adding debian:TrustCor_RootCert_CA-1.pem\n",
      "Adding debian:TrustCor_RootCert_CA-2.pem\n",
      "Adding debian:Trustis_FPS_Root_CA.pem\n",
      "Adding debian:UCA_Extended_Validation_Root.pem\n",
      "Adding debian:UCA_Global_G2_Root.pem\n",
      "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
      "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
      "Adding debian:VeriSign_Class_3_Public_Primary_Certification_Authority_-_G4.pem\n",
      "Adding debian:VeriSign_Class_3_Public_Primary_Certification_Authority_-_G5.pem\n",
      "Adding debian:VeriSign_Universal_Root_Certification_Authority.pem\n",
      "Adding debian:Verisign_Class_3_Public_Primary_Certification_Authority_-_G3.pem\n",
      "Adding debian:XRamp_Global_CA_Root.pem\n",
      "Adding debian:certSIGN_ROOT_CA.pem\n",
      "Adding debian:ePKI_Root_Certification_Authority.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
      "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
      "Adding debian:emSign_Root_CA_-_C1.pem\n",
      "Adding debian:emSign_Root_CA_-_G1.pem\n",
      "Adding debian:thawte_Primary_Root_CA.pem\n",
      "Adding debian:thawte_Primary_Root_CA_-_G2.pem\n",
      "Adding debian:thawte_Primary_Root_CA_-_G3.pem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Setting up default-jre-headless (2:1.11-71) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for libc-bin (2.28-10+deb10u1) ...\n",
      "Processing triggers for ca-certificates (20200601~deb10u2) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "\n",
      "done.\n",
      "done.\n",
      "Processing triggers for mime-support (3.62) ...\n",
      "Setting up openjdk-11-jre-headless:amd64 (11.0.16+8-1~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
      "Setting up openjdk-11-jre:amd64 (11.0.16+8-1~deb10u1) ...\n",
      "Setting up openjdk-11-jdk-headless:amd64 (11.0.16+8-1~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
      "Setting up default-jre (2:1.11-71) ...\n",
      "Setting up default-jdk-headless (2:1.11-71) ...\n",
      "Setting up openjdk-11-jdk:amd64 (11.0.16+8-1~deb10u1) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
      "Setting up default-jdk (2:1.11-71) ...\n",
      "Removing intermediate container 07407b4da94d\n",
      " ---> 4163f1e4a698\n",
      "Step 5/14 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 674b0457c25a\n",
      "Removing intermediate container 674b0457c25a\n",
      " ---> e7fcc1242a1d\n",
      "Step 6/14 : RUN pip --no-cache-dir install multi-model-server sagemaker-inference sagemaker-training\n",
      " ---> Running in 7cfb11ce9a78\n",
      "Collecting multi-model-server\n",
      "  Downloading multi_model_server-1.1.8-py2.py3-none-any.whl (6.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.4/6.4 MB 37.1 MB/s eta 0:00:00\n",
      "Collecting sagemaker-inference\n",
      "  Downloading sagemaker_inference-1.7.0.tar.gz (22 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting sagemaker-training\n",
      "  Downloading sagemaker_training-4.2.6.tar.gz (53 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.9/53.9 KB 170.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting model-archiver\n",
      "  Downloading model_archiver-1.0.3-py2.py3-none-any.whl (20 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 281.4/281.4 KB 213.3 MB/s eta 0:00:00\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-9.2.0-cp37-cp37m-manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 85.6 MB/s eta 0:00:00\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 829.2/829.2 KB 270.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 72.4 MB/s eta 0:00:00\n",
      "Collecting six\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting retrying==1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.1/38.1 MB 74.0 MB/s eta 0:00:00\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.24.64-py3-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.5/132.5 KB 244.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/site-packages (from sagemaker-training) (22.0.4)\n",
      "Collecting gevent\n",
      "  Downloading gevent-21.12.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 91.6 MB/s eta 0:00:00\n",
      "Collecting inotify_simple==1.2.1\n",
      "  Downloading inotify_simple-1.2.1.tar.gz (7.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting werkzeug>=0.15.5\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 KB 261.1 MB/s eta 0:00:00\n",
      "Collecting paramiko>=2.4.2\n",
      "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.9/212.9 KB 258.9 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 273.0 MB/s eta 0:00:00\n",
      "Collecting cryptography>=2.5\n",
      "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 93.0 MB/s eta 0:00:00\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-4.0.0-cp36-abi3-manylinux_2_28_x86_64.whl (594 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 594.4/594.4 KB 272.3 MB/s eta 0:00:00\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 KB 161.9 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting botocore<1.28.0,>=1.27.64\n",
      "  Downloading botocore-1.27.64-py3-none-any.whl (9.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.1/9.1 MB 87.5 MB/s eta 0:00:00\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.6/79.6 KB 205.6 MB/s eta 0:00:00\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 252.0/252.0 KB 266.8 MB/s eta 0:00:00\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from gevent->sagemaker-training) (57.5.0)\n",
      "Collecting greenlet<2.0,>=1.1.0\n",
      "  Downloading greenlet-1.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (150 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.7/150.7 KB 228.6 MB/s eta 0:00:00\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.4/140.4 KB 221.8 MB/s eta 0:00:00\n",
      "Collecting python-dateutil<3.0.0,>=2.1\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 KB 246.5 MB/s eta 0:00:00\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.15.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 427.9/427.9 KB 258.9 MB/s eta 0:00:00\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 118.7/118.7 KB 213.9 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sagemaker-inference, retrying, sagemaker-training, inotify_simple, future\n",
      "  Building wheel for sagemaker-inference (setup.py): started\n",
      "  Building wheel for sagemaker-inference (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-inference: filename=sagemaker_inference-1.7.0-py2.py3-none-any.whl size=28408 sha256=18441d52d39a5e289d7085dc6ecaf225ed562382edb2e5b03909e30bd3e9a773\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ra0lc6yt/wheels/4f/dd/0a/f2c955d3380fb9bb29473bc1bf65441eabb1c6c1442a21036d\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11447 sha256=44c00de0e185b2d7c9002f7585df42f6813c325164c9feafad522447eb87b6b8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ra0lc6yt/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
      "  Building wheel for sagemaker-training (setup.py): started\n",
      "  Building wheel for sagemaker-training (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker-training: filename=sagemaker_training-4.2.6-cp37-cp37m-linux_x86_64.whl size=87238 sha256=559e6d22b0c0a8e2788d743c4d129921ff8860f2ca31f30bf0c89a61055eb804\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ra0lc6yt/wheels/c5/07/03/cd23359207f78a637d947c2138f69275457e73c72764a59c8f\n",
      "  Building wheel for inotify_simple (setup.py): started\n",
      "  Building wheel for inotify_simple (setup.py): finished with status 'done'\n",
      "  Created wheel for inotify_simple: filename=inotify_simple-1.2.1-py3-none-any.whl size=8218 sha256=f9c70dc05f03a5cf6e249b4f5253d11e290c0532d6e9cc6f7699a3c8680b92ed\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ra0lc6yt/wheels/ef/7e/4a/bfeb3216a60ab5e077958f5a1e980cc3de9663155cfb31c660\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=66f3963a4972ab311a6f3ac1bdd0b07552a4fa7ea61df2314e0aef0c40417de8\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ra0lc6yt/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "Successfully built sagemaker-inference retrying sagemaker-training inotify_simple future\n",
      "Installing collected packages: inotify_simple, enum-compat, zope.interface, zope.event, urllib3, six, pycparser, psutil, protobuf, Pillow, numpy, MarkupSafe, jmespath, greenlet, future, bcrypt, werkzeug, scipy, retrying, python-dateutil, model-archiver, gevent, cffi, sagemaker-inference, pynacl, multi-model-server, cryptography, botocore, s3transfer, paramiko, boto3, sagemaker-training\n",
      "Successfully installed MarkupSafe-2.1.1 Pillow-9.2.0 bcrypt-4.0.0 boto3-1.24.64 botocore-1.27.64 cffi-1.15.1 cryptography-37.0.4 enum-compat-0.0.3 future-0.18.2 gevent-21.12.0 greenlet-1.1.3 inotify_simple-1.2.1 jmespath-1.0.1 model-archiver-1.0.3 multi-model-server-1.1.8 numpy-1.21.6 paramiko-2.11.0 protobuf-3.19.4 psutil-5.9.1 pycparser-2.21 pynacl-1.5.0 python-dateutil-2.8.2 retrying-1.3.3 s3transfer-0.6.0 sagemaker-inference-1.7.0 sagemaker-training-4.2.6 scipy-1.7.3 six-1.16.0 urllib3-1.26.12 werkzeug-2.2.2 zope.event-4.5.0 zope.interface-5.4.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 7cfb11ce9a78\n",
      " ---> b8c8a42341c9\n",
      "Step 7/14 : RUN pip --no-cache-dir install pandas numpy scipy scikit-learn\n",
      " ---> Running in c6ff4ba230af\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.3/11.3 MB 76.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (1.21.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (1.7.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.8/24.8 MB 73.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 500.6/500.6 KB 281.6 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.0/307.0 KB 258.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, threadpoolctl, joblib, scikit-learn, pandas\n",
      "Successfully installed joblib-1.1.0 pandas-1.3.5 pytz-2022.2.1 scikit-learn-1.0.2 threadpoolctl-3.1.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[91mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container c6ff4ba230af\n",
      " ---> 3b65fc9296bb\n",
      "Step 8/14 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in 4eaf51ecd6af\n",
      "Removing intermediate container 4eaf51ecd6af\n",
      " ---> f9d171426e2c\n",
      "Step 9/14 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in 08a242a089bf\n",
      "Removing intermediate container 08a242a089bf\n",
      " ---> f18ef4a1c1db\n",
      "Step 10/14 : ENV PYTHONPATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in a2ac724f0932\n",
      "Removing intermediate container a2ac724f0932\n",
      " ---> ad291ebd58ce\n",
      "Step 11/14 : COPY main.py /opt/ml/code/main.py\n",
      " ---> 8c54bd046f39\n",
      "Step 12/14 : COPY train.py /opt/ml/code/train.py\n",
      " ---> e442e17d2d95\n",
      "Step 13/14 : COPY handler.py /opt/ml/code/serving/handler.py\n",
      " ---> cee1f2c9a78e\n",
      "Step 14/14 : ENTRYPOINT [\"python\", \"/opt/ml/code/main.py\"]\n",
      " ---> Running in f1228ec0ce12\n",
      "Removing intermediate container f1228ec0ce12\n",
      " ---> 4d5e03e7f9d2\n",
      "Successfully built 4d5e03e7f9d2\n",
      "Successfully tagged iris_model:1.0\n"
     ]
    }
   ],
   "source": [
    "!docker build -f Dockerfile -t iris_model:1.0 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f5fc9",
   "metadata": {},
   "source": [
    "### 2.2 Now that we have the algorithm image we can run it to train/deploy a model\n",
    "### Then, we need to prepare the dataset\n",
    "You'll see that we're splitting the dataset into training and validation and also saving these two subsets of the dataset into csv files. These files will be then uploaded to an S3 Bucket and shared with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77e55fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iris_id</th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iris_id  sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0      0.0                5.1               3.5                1.4   \n",
       "1      0.0                4.9               3.0                1.4   \n",
       "2      0.0                4.7               3.2                1.3   \n",
       "3      0.0                4.6               3.1                1.5   \n",
       "4      0.0                5.0               3.6                1.4   \n",
       "\n",
       "   petal width (cm)  \n",
       "0               0.2  \n",
       "1               0.2  \n",
       "2               0.2  \n",
       "3               0.2  \n",
       "4               0.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm -rf input\n",
    "!mkdir -p input/data/train\n",
    "!mkdir -p input/data/validation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "dataset = np.insert(iris.data, 0, iris.target, axis=1)\n",
    "\n",
    "df= pd.DataFrame(data=dataset, columns=['iris_id'] + iris.feature_names)\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=123)\n",
    "\n",
    "train_df = X_train.copy()\n",
    "train_df.insert(0, \"iris_id\", y_train)\n",
    "train_df.to_csv(\"input/data/train/training.csv\", sep=',', header=None, index=None)\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df.insert(0, \"iris_id\", y_test)\n",
    "test_df.to_csv(\"input/data/validation/testing.csv\", sep=',', header=None, index=None)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba86d3",
   "metadata": {},
   "source": [
    "### 2.3 Just a basic local test, using the local Docker daemon\n",
    "Here we will simulate SageMaker calling our docker container for training and serving. We'll do that using the built-in Docker Daemon of the Jupyter Notebook Instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b834e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf input/config && mkdir -p input/config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7b30c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/hyperparameters.json\n",
    "{\"max_depth\":20, \"n_jobs\":4, \"n_setimators\":120}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9de4543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/resourceconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/resourceconfig.json\n",
    "{\"current_host\":\"localhost\", \"hosts\":[\"algo-1-kipw9\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b618ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/config/inputdataconfig.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/config/inputdataconfig.json\n",
    "{\"train\":{\"TrainingInputMode\":\"File\"}, \"validation\":{\"TrainingInputMode\":\"File\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5586f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training mode\n",
      "Training the classifier\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "Score: 0.94\n",
      "CPU times: user 35.7 ms, sys: 20.8 ms, total: 56.5 ms\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!rm -rf model\n",
    "!mkdir -p model\n",
    "print(\"Training...\")\n",
    "!docker run --rm --name \"my_model\" \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/model:/opt/ml/output\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8abffd",
   "metadata": {},
   "source": [
    "### 2.4 This is the serving test. It simulates an Endpoint exposed by Sagemaker\n",
    "After you execute the next cell, this Jupyter notebook will freeze. A webservice will be exposed at the port 8080."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9003751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: MMS is using non-default JVM parameters: -XX:-UseContainerSupport\n",
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2022-09-01T19:11:10,933 [INFO ] main com.amazonaws.ml.mms.ModelServer - \n",
      "MMS Home: /usr/local/lib/python3.7/site-packages\n",
      "Current directory: /\n",
      "Temp directory: /tmp\n",
      "Number of GPUs: 0\n",
      "Number of CPUs: 2\n",
      "Max heap size: 966 M\n",
      "Python executable: /usr/local/bin/python\n",
      "Config file: /etc/sagemaker-mms.properties\n",
      "Inference address: http://0.0.0.0:8080\n",
      "Management address: http://0.0.0.0:8080\n",
      "Model Store: /.sagemaker/mms/models\n",
      "Initial Models: ALL\n",
      "Log dir: null\n",
      "Metrics dir: null\n",
      "Netty threads: 0\n",
      "Netty client threads: 0\n",
      "Default workers per model: 2\n",
      "Blacklist Regex: N/A\n",
      "Maximum Response Size: 6553500\n",
      "Maximum Request Size: 6553500\n",
      "Preload model: false\n",
      "Prefer direct buffer: false\n",
      "2022-09-01T19:11:11,078 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\n",
      "2022-09-01T19:11:11,217 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /tmp/.mms.sock.9000 --handler serving.handler --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /tmp\n",
      "2022-09-01T19:11:11,221 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /tmp/.mms.sock.9000\n",
      "2022-09-01T19:11:11,223 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 33\n",
      "2022-09-01T19:11:11,224 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\n",
      "2022-09-01T19:11:11,225 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\n",
      "2022-09-01T19:11:11,227 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.7.13\n",
      "2022-09-01T19:11:11,233 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\n",
      "2022-09-01T19:11:11,268 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "2022-09-01T19:11:11,271 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /tmp/.mms.sock.9000\n",
      "2022-09-01T19:11:11,396 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\n",
      "Model server started.\n",
      "2022-09-01T19:11:11,407 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "2022-09-01T19:11:11,432 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /tmp/.mms.sock.9000.\n",
      "2022-09-01T19:11:11,463 [WARN ] pool-3-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\n",
      "2022-09-01T19:11:12,981 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe110002-0000000c-00000000-5c308b2ebf66e1bd-30aa5ae5\n",
      "2022-09-01T19:11:13,041 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1385\n",
      "2022-09-01T19:11:13,046 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\n",
      "2022-09-01T19:11:13,140 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242acfffe110002-0000000c-00000001-1a088b2ebf66e1bd-c0c86f76\n",
      "2022-09-01T19:11:13,140 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1488\n",
      "2022-09-01T19:11:13,141 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\n",
      "2022-09-01T19:11:46,743 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "2022-09-01T19:11:46,763 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "2022-09-01T19:11:46,790 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "2022-09-01T19:11:46,852 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 114\n",
      "2022-09-01T19:11:46,855 [INFO ] W-9000-model ACCESS_LOG - /172.17.0.1:46958 \"POST /invocations HTTP/1.1\" 200 124\n",
      "2022-09-01T19:11:46,916 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "2022-09-01T19:11:46,939 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "2022-09-01T19:11:46,954 [WARN ] W-model-1-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "2022-09-01T19:11:47,023 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 112\n",
      "2022-09-01T19:11:47,025 [INFO ] W-9000-model ACCESS_LOG - /172.17.0.1:46962 \"POST /invocations HTTP/1.1\" 200 116\n",
      "2022-09-01T19:11:47,044 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
      "2022-09-01T19:11:47,059 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
      "2022-09-01T19:11:47,074 [WARN ] W-model-2-stderr com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [Parallel(n_jobs=2)]: Done 120 out of 120 | elapsed:    0.0s finished\n",
      "2022-09-01T19:11:47,150 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 108\n",
      "2022-09-01T19:11:47,151 [INFO ] W-9000-model ACCESS_LOG - /172.17.0.1:46966 \"POST /invocations HTTP/1.1\" 200 110\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/ml/code/main.py\", line 33, in <module>\n",
      "    model_server.start_model_server(handler_service=\"serving.handler\")\n",
      "  File \"/usr/local/lib/python3.7/site-packages/sagemaker_inference/model_server.py\", line 104, in start_model_server\n",
      "    mms_process.wait()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/__init__.py\", line 1265, in wait\n",
      "    self._exitcode = self._proc.wait(timeout)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/_pslinux.py\", line 1642, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/_pslinux.py\", line 1848, in wait\n",
      "    return _psposix.wait_pid(self.pid, timeout, self._name)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/psutil/_psposix.py\", line 116, in wait_pid\n",
      "    retpid, status = os.waitpid(pid, flags)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm --name \"my_model\" \\\n",
    "    -p 8080:8080 \\\n",
    "    -v \"$PWD/model:/opt/ml/model\" \\\n",
    "    -v \"$PWD/input:/opt/ml/input\" iris_model:1.0 serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3632298",
   "metadata": {},
   "source": [
    " While the above cell is running, run some tests using **02_test_local_model_server.ipynb**\n",
    "\n",
    "After you finish the tests, press **STOP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f5052e",
   "metadata": {},
   "source": [
    "## PART 3 - Integrated Test: Everything seems ok, now it's time to put all together\n",
    "We'll start by running a local CodeBuild test, to check the buildspec and also deploy this image into the container registry. Remember that SageMaker will only see images published to ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3df00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "session = boto3.session.Session()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = session.region_name\n",
    "credentials = session.get_credentials()\n",
    "credentials = credentials.get_frozen_credentials()\n",
    "\n",
    "repo_name = \"iris-model\"\n",
    "image_tag = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6134b822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS_ACCOUNT_ID=523666378432\r\n",
      "IMAGE_TAG=test\r\n",
      "IMAGE_REPO_NAME=iris-model\r\n",
      "AWS_DEFAULT_REGION=ap-south-1\r\n",
      "AWS_ACCESS_KEY_ID=ASIAXT3HSZ3AFH2TSJOT\r\n",
      "AWS_SECRET_ACCESS_KEY=5lXiwOzgd0w3g8uIPwKePFOmOECzadl+bk/o0DNX\r\n",
      "AWS_SESSION_TOKEN=IQoJb3JpZ2luX2VjEPP//////////wEaCmFwLXNvdXRoLTEiSDBGAiEAoPzylGteK7I7wcyIATFvglL4oOKN9S8Wq8ODOHG3hvkCIQCSKqWPJWGtPKLH71GeCdGpVJHf0BMXs1AuvBfnxOw9hCq0Agh8EAAaDDUyMzY2NjM3ODQzMiIMLim1Jju7XbaVnJoNKpECCcmZKCCoD2CuDZvJ+Yc5J9bztQUHHEFTv3wQtQ/+nDw+nHumNjiiMknkkXbYZ4Rq/o8jUx9jzhlFTU4vBg64egVIWqpQc/PelN5CkJL3LCbsAg3dhDJ4p7ngkASuA6FCRTT0tOVdgSpX686zUPljL7yPiEblinGAcznAoBOvLy4Wo08v5YR8ZKMS5LwGUM/jRh1gD42Oc6wBmoGNaAoJhN6zNI51LuIDdHqYEeC9xaYlaQUAkyiG81MNy80MnyEprb+aJ2DgsO9X1GApMnNhHGKQR0gxIpqtFjZvgGXWs+HdnFloZfWarjyDpdTipVYbzH7QQntoA/bPxrKPRXvTRYRYhf83M7XY6C76H7EkvTd3MJyExJgGOpIBa/0SQXzo7eEqxri6dppuH1B7qLbrt2co1D0/iKbOcAdGgVhytWxuzTdbBN/AKRqXT8XN4utx3OiU4rPa9mS8xeXMuOGpaZal/dlcMJCAEHZMx0kv58M4cL2dXPVNk10DQkEVyXGTpyDB9u4hNO/uJjV33prUFunz3KO4zhdiPSjsmA4VGMipNC2PJsCD4sKyfB0=\r\n"
     ]
    }
   ],
   "source": [
    "!sudo rm -rf tests && mkdir -p tests\n",
    "!cp handler.py main.py train.py Dockerfile buildspec.yml tests/\n",
    "with open(\"tests/vars.env\", \"w\") as f:\n",
    "    f.write(\"AWS_ACCOUNT_ID=%s\\n\" % account_id)\n",
    "    f.write(\"IMAGE_TAG=%s\\n\" % image_tag)\n",
    "    f.write(\"IMAGE_REPO_NAME=%s\\n\" % repo_name)\n",
    "    f.write(\"AWS_DEFAULT_REGION=%s\\n\" % region)\n",
    "    f.write(\"AWS_ACCESS_KEY_ID=%s\\n\" % credentials.access_key)\n",
    "    f.write(\"AWS_SECRET_ACCESS_KEY=%s\\n\" % credentials.secret_key)\n",
    "    f.write(\"AWS_SESSION_TOKEN=%s\\n\" % credentials.token )\n",
    "    f.close()\n",
    "\n",
    "!cat tests/vars.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe33e2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /tmp/aws-codebuild/local_builds/codebuild_build.sh: No such file or directory\n",
      "CPU times: user 6.15 ms, sys: 3.79 ms, total: 9.94 ms\n",
      "Wall time: 122 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!/tmp/aws-codebuild/local_builds/codebuild_build.sh \\\n",
    "    -a \"$PWD/tests/output\" \\\n",
    "    -s \"$PWD/tests\" \\\n",
    "    -i \"samirsouza/aws-codebuild-standard:3.0\" \\\n",
    "    -e \"$PWD/tests/vars.env\" \\\n",
    "    -c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6d612",
   "metadata": {},
   "source": [
    "Now that we have an image deployed in the ECR repo we can also run some local tests using the SageMaker Estimator.\n",
    "\n",
    "Click on this TEST NOTEBOOK to run some tests.\n",
    "\n",
    "After you finishing the tests, come back to this notebook to push the assets to the Git Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfba562",
   "metadata": {},
   "source": [
    "## PART 4 - Let's push all the assets to the Git Repo connected to the Build pipeline\n",
    "There is a CodePipeine configured to keep listeining to this Git Repo and start a new Building process with CodeBuild."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34779e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[aws 390fe2f]  - files for building an iris model image\n",
      " 24 files changed, 3714 insertions(+), 12 deletions(-)\n",
      " create mode 100644 01_CreateAlgorithmContainer/.ipynb_checkpoints/02_test_local_model_server-checkpoint.ipynb\n",
      " create mode 100644 01_CreateAlgorithmContainer/.ipynb_checkpoints/03_test_container_using_SageMaker-checkpoint.ipynb\n",
      " create mode 100644 01_CreateAlgorithmContainer/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
      " create mode 100644 01_CreateAlgorithmContainer/02_test_local_model_server.ipynb\n",
      " create mode 100644 01_CreateAlgorithmContainer/03_test_container_using_SageMaker.ipynb\n",
      " create mode 100644 01_CreateAlgorithmContainer/Dockerfile\n",
      " create mode 100644 01_CreateAlgorithmContainer/Untitled.ipynb\n",
      " create mode 100644 01_CreateAlgorithmContainer/buildspec.yml\n",
      " create mode 100644 01_CreateAlgorithmContainer/handler.py\n",
      " create mode 100644 01_CreateAlgorithmContainer/input/config/hyperparameters.json\n",
      " create mode 100644 01_CreateAlgorithmContainer/input/config/inputdataconfig.json\n",
      " create mode 100644 01_CreateAlgorithmContainer/input/config/resourceconfig.json\n",
      " create mode 100644 01_CreateAlgorithmContainer/input/data/train/training.csv\n",
      " create mode 100644 01_CreateAlgorithmContainer/input/data/validation/testing.csv\n",
      " create mode 100644 01_CreateAlgorithmContainer/main.py\n",
      " create mode 100644 01_CreateAlgorithmContainer/model/iris_model.pkl\n",
      " create mode 100644 01_CreateAlgorithmContainer/tests/Dockerfile\n",
      " create mode 100644 01_CreateAlgorithmContainer/tests/buildspec.yml\n",
      " create mode 100644 01_CreateAlgorithmContainer/tests/handler.py\n",
      " create mode 100644 01_CreateAlgorithmContainer/tests/main.py\n",
      " create mode 100644 01_CreateAlgorithmContainer/tests/train.py\n",
      " create mode 100644 01_CreateAlgorithmContainer/tests/vars.env\n",
      " create mode 100644 01_CreateAlgorithmContainer/train.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: line 1: cd: ../../../mlops: No such file or directory\n",
      "error: pathspec 'iris_model' did not match any file(s) known to git\n",
      "cp: cannot stat ‘/buildspec.yml’: No such file or directory\n",
      "cp: cannot stat ‘/handler.py’: No such file or directory\n",
      "cp: cannot stat ‘/train.py’: No such file or directory\n",
      "cp: cannot stat ‘/main.py’: No such file or directory\n",
      "cp: cannot stat ‘/Dockerfile’: No such file or directory\n",
      "fatal: could not read Username for 'https://github.com/CrookedNoob/aws_mlops_practice.git': No such device or address\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'cd ../../../mlops\\ngit checkout iris_model\\ncp $OLDPWD/buildspec.yml $OLDPWD/handler.py $OLDPWD/train.py $OLDPWD/main.py $OLDPWD/Dockerfile .\\n\\ngit add --all\\ngit commit -a -m \" - files for building an iris model image\"\\ngit push\\n'' returned non-zero exit status 128.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7380/1162140208.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cd ../../../mlops\\ngit checkout iris_model\\ncp $OLDPWD/buildspec.yml $OLDPWD/handler.py $OLDPWD/train.py $OLDPWD/main.py $OLDPWD/Dockerfile .\\n\\ngit add --all\\ngit commit -a -m \" - files for building an iris model image\"\\ngit push\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2460\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2462\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2463\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cd ../../../mlops\\ngit checkout iris_model\\ncp $OLDPWD/buildspec.yml $OLDPWD/handler.py $OLDPWD/train.py $OLDPWD/main.py $OLDPWD/Dockerfile .\\n\\ngit add --all\\ngit commit -a -m \" - files for building an iris model image\"\\ngit push\\n'' returned non-zero exit status 128."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../../../mlops\n",
    "git checkout iris_model\n",
    "cp $OLDPWD/buildspec.yml $OLDPWD/handler.py $OLDPWD/train.py $OLDPWD/main.py $OLDPWD/Dockerfile .\n",
    "\n",
    "git add --all\n",
    "git commit -a -m \" - files for building an iris model image\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fd9a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
